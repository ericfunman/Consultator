#!/usr/bin/env python3
"""
Analyseur de performance pour l'application Consultator
Mesure les temps de r√©ponse des principales fonctions
"""

import os
import statistics
import sys
import time
from datetime import datetime

from sqlalchemy.exc import SQLAlchemyError

# Ajouter le chemin app au PYTHONPATH
sys.path.insert(0, os.path.join(os.getcwd(), "app"))


def measure_time(func, *args, **kwargs):
    """Mesure le temps d'ex√©cution d'une fonction"""
    start_time = time.time()
    result = func(*args, **kwargs)
    end_time = time.time()
    execution_time = end_time - start_time
    return result, execution_time


def analyze_consultant_service_performance():
    """Analyse les performances du service consultant"""

    print("üîç ANALYSE DES PERFORMANCES - CONSULTATOR")
    print("=" * 60)
    print(f"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    try:
        from services.consultant_service import ConsultantService

        # Tests multiples pour statistiques fiables
        num_tests = 5

        # Test 1: get_all_consultants (pagination standard)
        print("üìã TEST 1: get_all_consultants (50 premiers)")
        times_get_all = []

        for i in range(num_tests):
            result, exec_time = measure_time(
                ConsultantService.get_all_consultants, 1, 50
            )
            times_get_all.append(exec_time)
            print(f"  Test {i+1}: {exec_time:.3f}s - {len(result)} consultants")

        avg_get_all = statistics.mean(times_get_all)
        min_get_all = min(times_get_all)
        max_get_all = max(times_get_all)

        print("  üìä Statistiques:")
        print(f"    ‚Ä¢ Moyenne: {avg_get_all:.3f}s")
        print(f"    ‚Ä¢ Min: {min_get_all:.3f}s")
        print(f"    ‚Ä¢ Max: {max_get_all:.3f}s")
        print()

        # Test 2: search_consultants_optimized (recherche simple)
        print("üîç TEST 2: search_consultants_optimized ('Jean')")
        times_search = []

        for i in range(num_tests):
            result, exec_time = measure_time(
                ConsultantService.search_consultants_optimized, "Jean"
            )
            times_search.append(exec_time)
            print(f"  Test {i+1}: {exec_time:.3f}s - {len(result)} r√©sultats")

        avg_search = statistics.mean(times_search)
        min_search = min(times_search)
        max_search = max(times_search)

        print("  üìä Statistiques:")
        print(f"    ‚Ä¢ Moyenne: {avg_search:.3f}s")
        print(f"    ‚Ä¢ Min: {min_search:.3f}s")
        print(f"    ‚Ä¢ Max: {max_search:.3f}s")
        print()

        # Test 3: get_all_consultants_objects (objets SQLAlchemy)
        print("üèóÔ∏è TEST 3: get_all_consultants_objects (objets bruts)")
        times_objects = []

        for i in range(num_tests):
            result, exec_time = measure_time(
                ConsultantService.get_all_consultants_objects, 1, 50
            )
            times_objects.append(exec_time)
            print(f"  Test {i+1}: {exec_time:.3f}s - {len(result)} objets")

        avg_objects = statistics.mean(times_objects)
        min_objects = min(times_objects)
        max_objects = max(times_objects)

        print("  üìä Statistiques:")
        print(f"    ‚Ä¢ Moyenne: {avg_objects:.3f}s")
        print(f"    ‚Ä¢ Min: {min_objects:.3f}s")
        print(f"    ‚Ä¢ Max: {max_objects:.3f}s")
        print()

        # Test 4: Recherche sp√©cifique (Abdallah)
        print("üéØ TEST 4: search_consultants_optimized ('Abdallah')")
        times_specific = []

        for i in range(num_tests):
            result, exec_time = measure_time(
                ConsultantService.search_consultants_optimized, "Abdallah"
            )
            times_specific.append(exec_time)
            print(f"  Test {i+1}: {exec_time:.3f}s - {len(result)} r√©sultats")

        avg_specific = statistics.mean(times_specific)
        min_specific = min(times_specific)
        max_specific = max(times_specific)

        print("  üìä Statistiques:")
        print(f"    ‚Ä¢ Moyenne: {avg_specific:.3f}s")
        print(f"    ‚Ä¢ Min: {min_specific:.3f}s")
        print(f"    ‚Ä¢ Max: {max_specific:.3f}s")
        print()

        # Test 5: Grande pagination (stress test)
        print("‚ö° TEST 5: get_all_consultants (pagination large - 200)")
        times_large = []

        for i in range(3):  # Moins de tests car plus lourd
            result, exec_time = measure_time(
                ConsultantService.get_all_consultants, 1, 200
            )
            times_large.append(exec_time)
            print(f"  Test {i+1}: {exec_time:.3f}s - {len(result)} consultants")

        avg_large = statistics.mean(times_large)
        min_large = min(times_large)
        max_large = max(times_large)

        print("  üìä Statistiques:")
        print(f"    ‚Ä¢ Moyenne: {avg_large:.3f}s")
        print(f"    ‚Ä¢ Min: {min_large:.3f}s")
        print(f"    ‚Ä¢ Max: {max_large:.3f}s")
        print()

        # ANALYSE COMPARATIVE
        print("üìà ANALYSE COMPARATIVE")
        print("=" * 40)

        performance_data = [
            ("get_all_consultants (50)", avg_get_all, "Liste standard"),
            ("search_consultants ('Jean')", avg_search, "Recherche courante"),
            ("get_all_consultants_objects", avg_objects, "Objets bruts"),
            ("search_consultants ('Abdallah')", avg_specific, "Recherche sp√©cifique"),
            ("get_all_consultants (200)", avg_large, "Pagination large"),
        ]

        # Trier par performance
        performance_data.sort(key=lambda x: x[1])

        print("üèÜ CLASSEMENT PAR VITESSE:")
        for i, (test_name, avg_time, description) in enumerate(performance_data, 1):
            status = (
                "üöÄ"
                if avg_time < 0.1
                else "‚ö°"
                if avg_time < 0.5
                else "üêå"
                if avg_time > 1.0
                else "‚úÖ"
            )
            print(f"  {i}. {status} {test_name}: {avg_time:.3f}s ({description})")

        print()

        # RECOMMANDATIONS
        print("üí° RECOMMANDATIONS")
        print("=" * 40)

        if avg_get_all < 0.2:
            print("‚úÖ Performance EXCELLENTE pour la liste standard")
        elif avg_get_all < 0.5:
            print("‚ö° Performance BONNE pour la liste standard")
        else:
            print("‚ö†Ô∏è Performance √† am√©liorer pour la liste standard")

        if avg_search < 0.3:
            print("‚úÖ Recherche RAPIDE et optimis√©e")
        else:
            print("‚ö†Ô∏è Recherche pourrait √™tre optimis√©e")

        if avg_large > 1.0:
            print("‚ö†Ô∏è Pagination large lente - consid√©rer la limitation")
        else:
            print("‚úÖ Pagination large acceptable")

        # Ratio performance
        search_vs_list = avg_search / avg_get_all
        objects_vs_dict = avg_objects / avg_get_all

        print("\nüìä RATIOS:")
        print(f"  ‚Ä¢ Recherche vs Liste: {search_vs_list:.2f}x")
        print(f"  ‚Ä¢ Objets vs Dictionnaires: {objects_vs_dict:.2f}x")

        if search_vs_list < 1.5:
            print("  ‚úÖ Recherche bien optimis√©e par rapport √† la liste")
        else:
            print("  ‚ö†Ô∏è Recherche plus lente que pr√©vu")

        return {
            "get_all_avg": avg_get_all,
            "search_avg": avg_search,
            "objects_avg": avg_objects,
            "specific_avg": avg_specific,
            "large_avg": avg_large,
        }

    except (SQLAlchemyError, ValueError, TypeError, AttributeError) as e:
        print(f"‚ùå Erreur lors de l'analyse: {e}")
        import traceback

        traceback.print_exc()
        return None


def analyze_database_performance():
    """Analyse les performances de la base de donn√©es"""

    print("\nüóÑÔ∏è ANALYSE BASE DE DONN√âES")
    print("=" * 40)

    try:
        from database.database import get_database_session
        from database.models import Consultant
        from database.models import Mission
        from database.models import Practice

        # Test connexion DB
        start_time = time.time()
        session = get_database_session()
        connection_time = time.time() - start_time

        print(f"üîå Connexion DB: {connection_time:.3f}s")

        # Test count consultants
        start_time = time.time()
        count_consultants = session.query(Consultant).count()
        count_time = time.time() - start_time

        print(
            f"üìä Count consultants: {count_time:.3f}s ({count_consultants} consultants)"
        )

        # Test count missions
        start_time = time.time()
        count_missions = session.query(Mission).count()
        mission_count_time = time.time() - start_time

        print(
            f"üìã Count missions: {mission_count_time:.3f}s ({count_missions} missions)"
        )

        # Test requ√™te avec JOIN
        start_time = time.time()
        consultants_with_practice = (  # noqa: F841
            session.query(Consultant)
            .join(Practice, Consultant.practice_id == Practice.id, isouter=True)
            .limit(10)
            .all()
        )
        join_time = time.time() - start_time

        print(f"üîó Requ√™te JOIN (10 r√©sultats): {join_time:.3f}s")

        session.close()

        # √âvaluation performance DB
        if connection_time < 0.05:
            print("‚úÖ Connexion DB tr√®s rapide")
        elif connection_time < 0.1:
            print("‚ö° Connexion DB acceptable")
        else:
            print("‚ö†Ô∏è Connexion DB lente")

        if count_time < 0.1:
            print("‚úÖ Count tr√®s rapide")
        else:
            print("‚ö†Ô∏è Count pourrait √™tre optimis√©")

        return {
            "connection_time": connection_time,
            "count_time": count_time,
            "join_time": join_time,
            "total_consultants": count_consultants,
            "total_missions": count_missions,
        }

    except (SQLAlchemyError, ValueError, TypeError, AttributeError) as e:
        print(f"‚ùå Erreur DB: {e}")
        return None


def main():
    """Fonction principale d'analyse"""

    service_perf = analyze_consultant_service_performance()
    db_perf = analyze_database_performance()

    print("\nüéØ R√âSUM√â EX√âCUTIF")
    print("=" * 40)

    if service_perf and db_perf:
        # Score global
        avg_response = service_perf["get_all_avg"]

        if avg_response < 0.2:
            score = "A+ (EXCELLENT)"
            emoji = "üèÜ"
        elif avg_response < 0.5:
            score = "A (TR√àS BON)"
            emoji = "ü•á"
        elif avg_response < 1.0:
            score = "B (BON)"
            emoji = "ü•à"
        else:
            score = "C (√Ä AM√âLIORER)"
            emoji = "ü•â"

        print(f"{emoji} SCORE GLOBAL: {score}")
        print(f"üìä Temps de r√©ponse moyen: {avg_response:.3f}s")
        print(f"üë• Base de donn√©es: {db_perf['total_consultants']} consultants")
        print(f"üìã Missions: {db_perf['total_missions']} missions")

        # Recommandations finales
        print("\nüíé RECOMMANDATIONS FINALES:")
        if avg_response < 0.3:
            print("  ‚úÖ Application tr√®s performante - RAS")
        elif avg_response < 0.7:
            print("  ‚ö° Performance correcte - monitoring recommand√©")
        else:
            print("  ‚ö†Ô∏è Optimisations n√©cessaires:")
            print("    ‚Ä¢ Ajouter des index sur les colonnes de recherche")
            print("    ‚Ä¢ Impl√©menter un cache Redis")
            print("    ‚Ä¢ Optimiser les requ√™tes SQL")

    print(f"\nüìù Analyse termin√©e le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
